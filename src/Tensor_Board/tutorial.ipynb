{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce144510",
   "metadata": {},
   "source": [
    "# Tutorial for Tensor Board in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02247f07",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0a58a",
   "metadata": {},
   "source": [
    "Tensor Board is supported in `torch.utils.tensorboard`.\n",
    "\n",
    "Docs: [Docs for tensor board](https://docs.pytorch.org/docs/stable//tensorboard.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348a234",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Actually you only need to install `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2880fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08080d23",
   "metadata": {},
   "source": [
    "## Quick Setup\n",
    "\n",
    "To use Tensor Board quickly, run this command as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial for using tensor board\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "print(torch.__version__)\n",
    "print(f\"Numbers of GPU available: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "trainset = datasets.MNIST(\n",
    "    \"data/mnist_train\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "model = torchvision.models.resnet50(weights=None)\n",
    "# Have ResNet model take in grayscale rather than RGB\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image(\"images\", grid, 0)\n",
    "writer.add_graph(model, images)\n",
    "writer.close()\n",
    "\n",
    "# then run tensor board in the command line!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b56698",
   "metadata": {},
   "source": [
    "Then you can open Tensor Board via this command:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=./log\n",
    "```\n",
    "\n",
    "or \n",
    "```bash\n",
    "python -m tensorboard.main --logdir=./log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3bbc4",
   "metadata": {},
   "source": [
    "## SummaryWriter\n",
    "\n",
    "The **SummaryWriter** class provides a high-level API to create an event file in a given directory and add summaries and events to it. The class updates the file contents asynchronously. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae852f61",
   "metadata": {},
   "source": [
    "### Scalars\n",
    "\n",
    "You can write Scalars into Tensor Board.\n",
    "\n",
    "This is one of the most common things to log. You can use add_scalar() to record a single numerical value, such as a loss or accuracy, at each training step. This is great for tracking your model's performance over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c4068b",
   "metadata": {},
   "source": [
    "#### Adding scalars for single data\n",
    "\n",
    "Parameters:\n",
    "\n",
    "- `tag` (str) – Data identifier\n",
    "\n",
    "- `scalar_value` (float or string/blobname) – Value to save\n",
    "\n",
    "- `global_step` (int) – Global step value to record\n",
    "\n",
    "- `walltime` (float) – Optional override default walltime (time.time()) with seconds after epoch of event\n",
    "\n",
    "- `new_style` (boolean) – Whether to use new style (tensor field) or old style (simple_value field). New style could lead to faster data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"test_dir\")\n",
    "\n",
    "for n_iter in range(50):\n",
    "    writer.add_scalar(\"Loss/train\", np.random.random(), n_iter)\n",
    "    writer.add_scalar(\"Loss/test\", np.random.random(), n_iter)\n",
    "    writer.add_scalar(\"Accuracy/train\", np.random.random(), n_iter)\n",
    "    writer.add_scalar(\"Accuracy/test\", np.random.random(), n_iter)\n",
    "\n",
    "# then you can see the curve generated randomly in the Tensor Board!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_2 = SummaryWriter(log_dir=\"test_dir\")\n",
    "\n",
    "\n",
    "def test_func(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "for n_iter in range(50):\n",
    "    writer_2.add_scalar(\"test_1/test_2\", test_func(n_iter), n_iter)\n",
    "\n",
    "writer_2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176470a1",
   "metadata": {},
   "source": [
    "#### Adding Scalar for many data\n",
    "\n",
    "Add many scalar data to summary.\n",
    "\n",
    "Parameters\n",
    "\n",
    "- `main_tag` (str) – The parent name for the tags\n",
    "\n",
    "- `tag_scalar_dict` (dict) – **Key-value pair** storing the tag and corresponding values (It is a **dict**!)\n",
    "\n",
    "- `global_step` (int) – Global step value to record\n",
    "\n",
    "- `walltime` (float) – Optional override default walltime (time.time()) seconds after epoch of event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baebb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "r = 5\n",
    "for i in range(100):\n",
    "    writer_2.add_scalars(\n",
    "        \"run_14h\",\n",
    "        {\n",
    "            \"xsinx\": i * np.sin(i / r),\n",
    "            \"xcosx\": i * np.cos(i / r),\n",
    "            \"tanx\": np.tan(i / r),\n",
    "        },  # return multiple functions\n",
    "        i,\n",
    "    )\n",
    "\n",
    "# !remember to add this line like plt.close()!\n",
    "writer_2.close()\n",
    "\n",
    "# This call adds three values to the same scalar plot with the tag\n",
    "# 'run_14h' in TensorBoard's scalar section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a246d2e",
   "metadata": {},
   "source": [
    "### Images and videos\n",
    "\n",
    "#### Add single image\n",
    "\n",
    "Parameters\n",
    "\n",
    "- `tag` (str) – Data identifier\n",
    "\n",
    "- `img_tensor` (**torch.Tensor, numpy.ndarray, or string/blobname**) – Image data\n",
    "\n",
    "- `global_step` (int) – Global step value to record\n",
    "\n",
    "- `walltime` (float) – Optional override default walltime (time.time()) seconds after epoch of event\n",
    "\n",
    "- `dataformats` (str) – Image data format specification of the form CHW, HWC, HW, WH, etc.\n",
    "\n",
    "img_tensor: Default is $(3, H, W)$, (**CHW**: Channel, Height, Width).\n",
    "\n",
    "More dataformats include:\n",
    "\n",
    "- $(1, H, W)$: for grey images which have only one channel. **CHW**\n",
    "\n",
    "- $(H, W)$: **HW**\n",
    "\n",
    "- $(H, W, 3)$: **HWC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a351ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "# demo 1: add a image\n",
    "img = np.zeros((3, 100, 100))\n",
    "img[0] = np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "\n",
    "img_HWC = np.zeros((100, 100, 3))\n",
    "img_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "img_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "\n",
    "writer = SummaryWriter(\"test_dir\")\n",
    "writer.add_image(\"my_image\", img, 0)\n",
    "\n",
    "# demo 2: generate a random tensor for simulation\n",
    "for step in range(10):\n",
    "    img_random = np.zeros((3, 100, 100))\n",
    "    for i in range(3):\n",
    "        img_random[i] = np.random.random((100, 100))\n",
    "    writer.add_image(\"random_image\", img_random, step)\n",
    "\n",
    "# If you have non-default dimension setting, set the dataformats argument.\n",
    "writer.add_image(\"my_image_HWC\", img_HWC, 0, dataformats=\"HWC\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9c85a3",
   "metadata": {},
   "source": [
    "#### Add multiple images\n",
    "\n",
    "Add batched image data to summary.\n",
    "\n",
    "Note that this requires the pillow package.\n",
    "\n",
    "Parameters\n",
    "\n",
    "- `tag` (str) – Data identifier\n",
    "\n",
    "- `img_tensor` (torch.Tensor, numpy.ndarray, or string/blobname) – Image data\n",
    "\n",
    "- `global_step` (int) – Global step value to record\n",
    "\n",
    "- `walltime` (float) – Optional override default walltime (time.time()) seconds after epoch of event\n",
    "\n",
    "- `dataformats` (str) – Image data format specification of the form NCHW, NHWC, CHW, HWC, HW, WH, etc.\n",
    "\n",
    "Compared to `add_image`, it will add one dimension for **batches**, where the image_tensor is $(N, 3, H, W)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bdd011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "img_batches = np.zeros((16, 3, 100, 100))\n",
    "\n",
    "for step in range(16):\n",
    "    for channel in range(3):\n",
    "        img_batches[step, channel] = (\n",
    "            np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * step\n",
    "        )\n",
    "\n",
    "writer.add_images(\"test for batches\", img_batches, 1, dataformats=\"NCHW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5f459",
   "metadata": {},
   "source": [
    "`add_figure(tag, figure, global_step=None, close=True, walltime=None)`: \n",
    "    Render **matplotlib** figure into an image and add it to summary.\n",
    "\n",
    "Parameters\n",
    "\n",
    "- tag (str) – Data identifier\n",
    "\n",
    "- `figure` (Union[Figure, list['Figure']]) – Figure or a list of figures\n",
    "\n",
    "- global_step (Optional[int]) – Global step value to record\n",
    "\n",
    "- close (bool) – Flag to automatically close the figure\n",
    "\n",
    "- walltime (Optional[float]) – Optional override default walltime (time.time()) seconds after epoch of event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "writer = SummaryWriter(\"test_dir/figure\")\n",
    "\n",
    "# generate a matplotlib image\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(0, 2 * np.pi, 100)\n",
    "y = np.cos(x)\n",
    "ax.plot(x, y)\n",
    "ax.set_title(\"Cos(x)\")\n",
    "\n",
    "writer.add_figure(\"cos_plot\", fig, global_step=0)\n",
    "\n",
    "plt.close(fig)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a318a9",
   "metadata": {},
   "source": [
    "### Text\n",
    "\n",
    "Parameters\n",
    "\n",
    "- `tag` (str) – Data identifier\n",
    "\n",
    "- `text_string` (str) – String to save\n",
    "\n",
    "- `global_step` (int) – Global step value to record\n",
    "\n",
    "- `walltime` (float) – Optional override default walltime (time.time()) seconds after epoch of event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1c876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_3 = SummaryWriter(\"test_dir/test_for_text\")\n",
    "writer_3.add_text(\"tag-1\", \"Hello world\")\n",
    "writer_3.add_text(\"tag-2\", \"wow, this is fanastic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e99f99",
   "metadata": {},
   "source": [
    "### Graph\n",
    "\n",
    "add_graph(model, input_to_model=None, verbose=False, use_strict_trace=True)[source][source]\n",
    "Add graph data to summary.\n",
    "\n",
    "Parameters\n",
    "\n",
    "- `model` (torch.nn.Module) – Model to draw.\n",
    "\n",
    "- `input_to_model` (torch.Tensor or list of torch.Tensor) – A variable or a tuple of variables to be fed.\n",
    "\n",
    "- `verbose` (bool) – Whether to print graph structure in console.\n",
    "\n",
    "- `use_strict_trace` (bool) – Whether to pass keyword argument strict to torch.jit.trace. Pass False when you want the tracer to record your mutable container types (list, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eaf251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# Define a simplified model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleModel()\n",
    "writer = SummaryWriter(\"test_dir/test_graph\")\n",
    "\n",
    "dummy_input = torch.randn(1, 10)  # (batch_size, input_dim)\n",
    "\n",
    "writer.add_graph(model, dummy_input, verbose=True)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5eedbc",
   "metadata": {},
   "source": [
    "![image](https://s1.imagehub.cc/images/2025/07/01/f4bfc3177a9f6f53af4d0510df5a20b4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3d7e0",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "`add_embedding(mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None)`\n",
    "\n",
    "Add embedding projector data to summary.\n",
    "\n",
    "- `mat` (torch.Tensor or numpy.ndarray) – A matrix which each row is the feature vector of the data point, its size is $(N, D)$, where $N$ is the number of data and $D$ is the feature dimension.\n",
    "\n",
    "- `metadata` (list) – A list of labels, each element will be converted to string\n",
    "\n",
    "- `label_img` (torch.Tensor) – Images correspond to each data point, $(N, C, H, W)$.\n",
    "\n",
    "- `global_step` (int) – Global step value to record\n",
    "\n",
    "- `tag` (str) – Name for the embedding\n",
    "\n",
    "- `metadata_header` (list) – A list of headers for multi-column metadata. If given, each metadata must be a list with values corresponding to headers.\n",
    "\n",
    "![image](https://s1.imagehub.cc/images/2025/07/01/9c90c770dfda3461dd63f1f59fce0d49.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f954c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyword\n",
    "import torch\n",
    "\n",
    "# keyword is for auto-generation\n",
    "\n",
    "meta = []\n",
    "while len(meta) < 100:\n",
    "    meta = meta + keyword.kwlist  # get some strings\n",
    "meta = meta[:100]\n",
    "\n",
    "for i, v in enumerate(meta):\n",
    "    meta[i] = v + str(i)\n",
    "\n",
    "label_img = torch.rand(100, 3, 10, 32)\n",
    "for i in range(100):\n",
    "    label_img[i] *= i / 100.0\n",
    "\n",
    "# print(meta)\n",
    "print(len(meta))  #: 100\n",
    "# print(label_img)\n",
    "\n",
    "\n",
    "# define writer\n",
    "writer = SummaryWriter(\"test_dir/test_for_embedding\")\n",
    "writer.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)\n",
    "writer.add_embedding(torch.randn(100, 5), label_img=label_img)\n",
    "writer.add_embedding(torch.randn(100, 5), metadata=meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d499c",
   "metadata": {},
   "source": [
    "`add_pr_curve(tag, labels, predictions, global_step=None, num_thresholds=127, weights=None, walltime=None)`\n",
    "\n",
    "**Add precision recall curve**.\n",
    "\n",
    "Plotting a precision-recall curve lets you understand your model’s performance under different threshold settings. With this function, you provide the ground truth labeling (T/F) and prediction confidence (usually the output of your model) for each target. The TensorBoard UI will let you choose the threshold interactively.\n",
    "\n",
    "$$\\text{Precision} = \\frac{\\text{True Positive}}{\\text{True Positive} + \\text{False Positive}}$$\n",
    "\n",
    "$$\\text{Recall} = \\frac{\\text{True Positive}}{\\text{True Positive} + \\text{False Negative}}$$\n",
    "\n",
    "Parameters\n",
    "\n",
    "- `tag` (str) – Data identifier\n",
    "\n",
    "- `labels` (torch.Tensor, numpy.ndarray, or string/blobname) – Ground truth data. Binary label for each element.\n",
    "\n",
    "- `predictions` (torch.Tensor, numpy.ndarray, or string/blobname) – The probability that an element be classified as true. Value should be in [0, 1]\n",
    "\n",
    "- `global_step` (int) – Global step value to record\n",
    "\n",
    "- `num_thresholds` (int) – Number of thresholds used to draw the curve.\n",
    "\n",
    "- `walltime` (float) – Optional override default walltime (time.time()) seconds after epoch of event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec031dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "labels = np.random.randint(2, size=1000)  # binary label\n",
    "predictions = np.random.rand(1000)\n",
    "writer = SummaryWriter(\"test_dir/pr_curve_2\")\n",
    "writer.add_pr_curve(\"pr_curve\", labels, predictions, 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87635ca9",
   "metadata": {},
   "source": [
    "### Mesh\n",
    "\n",
    "Add meshes or 3D point clouds to TensorBoard.\n",
    "\n",
    "The visualization is based on Three.js, so it allows users to interact with the rendered object. Besides the basic definitions such as vertices, faces, users can further provide camera parameter, lighting condition, etc. Please check https://threejs.org/docs/index.html#manual/en/introduction/Creating-a-scene for advanced usage.\n",
    "\n",
    "Parameters\n",
    "\n",
    "- `tag` (str) – Data identifier\n",
    "\n",
    "- `vertices` (torch.Tensor) – List of the 3D coordinates of vertices. (**顶点坐标**)\n",
    "\n",
    "- `colors` (torch.Tensor) – Colors for each vertex. (**顶点颜色**)\n",
    "\n",
    "- `faces` (torch.Tensor) – Indices of vertices within each triangle. (Optional) (**面片索引**)\n",
    "\n",
    "- `config_dict` – Dictionary with ThreeJS classes names and configuration.\n",
    "\n",
    "- `global_step` (int) – Global step value to record\n",
    "\n",
    "- `walltime` (float) – Optional override default walltime (time.time()) seconds after epoch of event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca85fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "vertices_tensor = torch.as_tensor(\n",
    "    [\n",
    "        [1, 1, 1],\n",
    "        [-1, -1, 1],\n",
    "        [1, -1, -1],\n",
    "        [-1, 1, -1],\n",
    "    ],\n",
    "    dtype=torch.float,\n",
    ").unsqueeze(0)\n",
    "# print(vertices_tensor.shape): (1,4,3), where 1 is the batch size and 4 is the number of vertices\n",
    "\n",
    "colors_tensor = torch.as_tensor(\n",
    "    [\n",
    "        [255, 0, 0],\n",
    "        [0, 255, 0],\n",
    "        [0, 0, 255],\n",
    "        [255, 0, 255],\n",
    "    ],\n",
    "    dtype=torch.int,\n",
    ").unsqueeze(0)\n",
    "# print(colors_tensor.shape): (1,4,3), the same as above\n",
    "\n",
    "faces_tensor = torch.as_tensor(\n",
    "    [\n",
    "        [0, 2, 3],\n",
    "        [0, 3, 1],\n",
    "        [0, 1, 2],\n",
    "        [1, 3, 2],\n",
    "    ],\n",
    "    dtype=torch.int,\n",
    ").unsqueeze(0)\n",
    "\n",
    "writer = SummaryWriter(\"test_dir/test_mesh\")\n",
    "writer.add_mesh(\n",
    "    \"my_mesh\", vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor\n",
    ")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40888f6a",
   "metadata": {},
   "source": [
    "### Hparams\n",
    "\n",
    "Add a set of hyperparameters to be compared in TensorBoard.\n",
    "\n",
    "- `hparam_dict` (dict) – Each **key-value pair** in the dictionary is the name of the hyper parameter and it’s corresponding value. The type of the value can be one of **bool**, **string**, **float**, **int**, or None.\n",
    "\n",
    "- `metric_dict` (dict) – Each key-value pair in the dictionary is the name of the metric and it’s corresponding value. Note that **the key used here should be unique in the tensorboard record**. Otherwise the value you added by add_scalar will be displayed in hparam plugin. In most cases, this is unwanted.\n",
    "\n",
    "- `hparam_domain_discrete` – (Optional[Dict[str, List[Any]]]) A dictionary that contains names of the hyperparameters and all discrete values they can hold\n",
    "\n",
    "- `run_name` (str) – Name of the run, to be included as part of the logdir. If unspecified, will use current timestamp.\n",
    "\n",
    "- `global_step` (int) – Global step value to record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bce7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "with SummaryWriter(\"test_dir/hparams\") as w:\n",
    "    for i in range(5):\n",
    "        w.add_hparams(\n",
    "            {\"lr\": 0.1 * i, \"bsize\": i},\n",
    "            {\"hparam/accuracy\": 10 * i, \"hparam/loss\": 10 * i},\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd6269",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fbf1aa",
   "metadata": {},
   "source": [
    "In this section, we will train a complex model (CNN + LSTM + Transformer), and use `SummaryWriter` to log loss curve and other parameters.\n",
    "\n",
    "![Demo for loss curve](https://s1.imagehub.cc/images/2025/07/02/cf43cf56c80afd47a0104b86594f2cd3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2af0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter('runs/exp_demo')\n",
    "\n",
    "class ComplexModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN feature\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.AdaptiveAvgPool2d((4, 4))\n",
    "        )\n",
    "        \n",
    "        # LSTM section\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=64*4*4, \n",
    "            hidden_size=128, \n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # attention section\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input shape: (batch_size, seq_len, C, H, W)\n",
    "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
    "        \n",
    "        cnn_features = []\n",
    "        for t in range(seq_len):\n",
    "            frame = x[:, t, :, :, :]\n",
    "            features = self.cnn(frame)  # (bs, 64, 4, 4)\n",
    "            features = features.view(batch_size, -1)  # (bs, 64*4*4)\n",
    "            cnn_features.append(features)\n",
    "        \n",
    "        cnn_features = torch.stack(cnn_features, dim=1)  # (bs, seq_len, 64*4*4)\n",
    "        lstm_out, _ = self.lstm(cnn_features)  # (bs, seq_len, 256)\n",
    "        attention_weights = self.attention(lstm_out)  # (bs, seq_len, 1)\n",
    "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)  # (bs, 256)\n",
    "        return self.classifier(context_vector)\n",
    "\n",
    "# 3. 创建模拟数据 (视频分类任务)\n",
    "def generate_fake_data(batch_size=16, seq_len=10):\n",
    "    # 生成随机视频数据 (batch, seq_len, 3, 64, 64)\n",
    "    videos = torch.randn(batch_size, seq_len, 3, 64, 64)\n",
    "    labels = torch.randint(0, 10, (batch_size,))\n",
    "    return videos, labels\n",
    "\n",
    "train_data, train_labels = generate_fake_data(100)\n",
    "val_data, val_labels = generate_fake_data(20)\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "val_dataset = TensorDataset(val_data, val_labels)\n",
    "\n",
    "model = ComplexModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "def train(model, dataloader, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        if batch_idx % 5 == 0:  \n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    writer.add_histogram(\n",
    "                        f\"Gradients/{name}\", \n",
    "                        param.grad, \n",
    "                        epoch * len(dataloader) + batch_idx\n",
    "                    )\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            for name, param in model.named_parameters():\n",
    "                writer.add_histogram(\n",
    "                    f\"Parameters/{name}\", \n",
    "                    param, \n",
    "                    epoch\n",
    "                )\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "    \n",
    "    accuracy = correct / len(dataloader.dataset)\n",
    "    writer.add_scalar('Accuracy/val', accuracy, epoch)\n",
    "    return accuracy\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train(model, train_loader, epoch)\n",
    "    val_acc = validate(model, val_loader, epoch)\n",
    "    \n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    if epoch == 0:\n",
    "        dummy_input = torch.randn(1, 10, 3, 64, 64)  \n",
    "        writer.add_graph(model, dummy_input)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
